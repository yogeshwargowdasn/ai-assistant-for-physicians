{% extends "base.html" %}
{% block title %}Speech to Text{% endblock %}

{% block content %}
<div class="container mt-4">
  <a href="{{ url_for('auth.dashboard') }}" class="btn btn-secondary mb-3">Back to Dashboard</a>
  <h2>ğŸ™ Speak Your Symptoms</h2>

  <button class="btn btn-primary" onclick="startRecording()">ğŸ¤ Start Recording (5 sec)</button>
  <div id="loader" class="mt-2 text-warning" style="display: none;">â³ Listening & processing...</div>

  <div class="mt-4">
    <label for="transcriptBox"><strong>ğŸ“ Detected Text:</strong></label>
    <textarea id="transcriptBox" class="form-control" rows="4" readonly></textarea>
    <button class="btn btn-success mt-2" onclick="copyText()">ğŸ“‹ Copy to Clipboard</button>
  </div>
</div>

<script>
  let mediaRecorder;
  let audioChunks = [];

  async function startRecording() {
    audioChunks = [];
    document.getElementById("loader").style.display = "block";

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);

    mediaRecorder.ondataavailable = event => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioContext = new AudioContext();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      const wavBlob = await encodeWAV(audioBuffer);

      const formData = new FormData();
      formData.append('audio', wavBlob, 'recording.wav');

      const response = await fetch('/ai/speech-to-text', {
        method: 'POST',
        body: formData
      });

      const result = await response.json();
      document.getElementById("loader").style.display = "none";
      if (result.transcript) {
        document.getElementById('transcriptBox').value = result.transcript;
      } else {
        document.getElementById('transcriptBox').value = "[Error] " + result.error;
      }
    };

    mediaRecorder.start();
    setTimeout(() => mediaRecorder.stop(), 5000);
  }

  async function encodeWAV(audioBuffer) {
    const numChannels = 1;
    const sampleRate = audioBuffer.sampleRate;
    const length = audioBuffer.length * 2;
    const buffer = new ArrayBuffer(44 + length);
    const view = new DataView(buffer);

    function writeString(view, offset, str) {
      for (let i = 0; i < str.length; i++) {
        view.setUint8(offset + i, str.charCodeAt(i));
      }
    }

    const samples = audioBuffer.getChannelData(0);
    let offset = 0;

    writeString(view, 0, 'RIFF'); offset += 4;
    view.setUint32(offset, 36 + length, true); offset += 4;
    writeString(view, offset, 'WAVE'); offset += 4;
    writeString(view, offset, 'fmt '); offset += 4;
    view.setUint32(offset, 16, true); offset += 4;
    view.setUint16(offset, 1, true); offset += 2;
    view.setUint16(offset, numChannels, true); offset += 2;
    view.setUint32(offset, sampleRate, true); offset += 4;
    view.setUint32(offset, sampleRate * 2, true); offset += 4;
    view.setUint16(offset, 2, true); offset += 2;
    view.setUint16(offset, 16, true); offset += 2;
    writeString(view, offset, 'data'); offset += 4;
    view.setUint32(offset, length, true); offset += 4;

    let index = 44;
    for (let i = 0; i < samples.length; i++) {
      const s = Math.max(-1, Math.min(1, samples[i]));
      view.setInt16(index, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      index += 2;
    }

    return new Blob([view], { type: 'audio/wav' });
  }

  function copyText() {
    const textBox = document.getElementById("transcriptBox");
    textBox.select();
    document.execCommand("copy");
    alert("Copied to clipboard!");
  }
</script>
{% endblock %}
